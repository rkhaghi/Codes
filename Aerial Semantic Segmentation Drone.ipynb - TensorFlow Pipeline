{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gSczf8IGPh8Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.models import Model\n",
        "# from keras.layers import (Input, \n",
        "#                           Conv2D, \n",
        "#                           MaxPooling2D,\n",
        "#                           concatenate, \n",
        "#                           Conv2DTranspose,\n",
        "#                           BatchNormalization,\n",
        "#                           Dropout)\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras import backend as K\n",
        "import pathlib\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZotK6RYTP4Vb"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/archive5/dataset/semantic_drone_dataset/'\n",
        "\n",
        "list_images = tf.data.Dataset.list_files([str(i) for i in pathlib.Path(data_dir).glob('**/*.jpg')], shuffle=False)\n",
        "list_labels = tf.data.Dataset.list_files([str(i) for i in pathlib.Path(data_dir).glob('**/*.png')], shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "rgb_df = pd.read_csv(data_dir+ 'class_dict_seg.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XyYricVySaO0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def process_image_jpg(image):\n",
        "    image = tf.io.read_file(image)\n",
        "    image = tf.image.decode_jpeg(image)\n",
        "    image = tf.image.resize(image, [1536,1024], method='nearest')\n",
        "    return image\n",
        "\n",
        "def process_image_png(image):\n",
        "    image = tf.io.read_file(image)\n",
        "    image = tf.image.decode_png(image)\n",
        "    image = tf.image.resize(image, [1536,1024], method='nearest')\n",
        "    return image\n",
        "\n",
        "\n",
        "def patchify1(image):\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "    image= tf.reshape(tf.image.extract_patches(images=image,\n",
        "                        sizes=[1, 256, 256, 1],\n",
        "                        strides=[1, 256, 256, 1],\n",
        "                        rates=[1, 1, 1, 1],\n",
        "                        padding='VALID'),(6*4,256,256))\n",
        "    return image\n",
        "    \n",
        "def patchify3(image):\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "    image= tf.reshape(tf.image.extract_patches(images=image,\n",
        "                        sizes=[1, 256, 256, 1],\n",
        "                        strides=[1, 256, 256, 1],\n",
        "                        rates=[1, 1, 1, 1],\n",
        "                        padding='VALID'),(6*4,256,256,3))\n",
        "    \n",
        "\n",
        "    return image\n",
        " \n",
        "\n",
        "def scale(image):\n",
        "    image = image/255\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "# def rgb_to_labels(label):\n",
        "#         for i in range(0,len(classes)):#len(classes)-20):\n",
        "#             class_array = tf.reshape(tf.multiply(tf.ones([256*256*3], tf.uint8), i+1),[256,256,3])\n",
        "#             condition = tf.equal(label,classes[i])\n",
        "#             label = tf.where(condition, class_array, label)\n",
        "#         label = label[:,:,:,1]\n",
        "            \n",
        "#         return label\n",
        "    \n",
        "\n",
        "def to_categorical(label):\n",
        "    #images = tf.cast(images, tf.float32)/255.\n",
        "     label = tf.one_hot(label,depth = 23)\n",
        "     \n",
        "     return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AlR7D1ZkSlf1"
      },
      "outputs": [],
      "source": [
        "image = list_images.map(process_image_jpg).map(scale).map(patchify3)\n",
        "label = list_labels.map(process_image_png).map(patchify1).map(to_categorical)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uB1WP-7KE7mE"
      },
      "outputs": [],
      "source": [
        "\n",
        "def split_data(image, label):\n",
        "    \n",
        "    dataset_size = (tf.data.experimental.cardinality(image)).numpy()\n",
        "    image = image.take(dataset_size)\n",
        "    label = label.take(dataset_size)\n",
        "    train_size= int(0.8 * dataset_size)\n",
        "    val_size= int(0.1 * dataset_size)\n",
        "    test_size= int(0.1 * dataset_size)\n",
        "    X_train_data = image.take(train_size)\n",
        "    X_val_data = image.skip(train_size)\n",
        "    X_test_data = X_val_data.skip(val_size)\n",
        "    X_val_data = X_val_data.take(val_size)\n",
        "    Y_train_data = label.take(train_size)\n",
        "    Y_val_data = label.skip(train_size)\n",
        "    Y_test_data = Y_val_data.skip(val_size)\n",
        "    Y_val_data = Y_val_data.take(val_size)\n",
        "    \n",
        "    \n",
        "    return X_train_data,X_val_data,X_test_data, Y_train_data,Y_val_data, Y_test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XSIerVoYFAQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404055d8-eff9-4eb0-c90f-963b43fc8a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24, 8, 8, 2048)\n",
            "(None, 256, 256, 23)\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " xception (Functional)       (None, 8, 8, 2048)        20861480  \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 16, 16, 256)      2097408   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2DT  (None, 32, 32, 128)      131200    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_7 (Conv2DT  (None, 64, 64, 64)       32832     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_8 (Conv2DT  (None, 128, 128, 32)     8224      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 128, 128, 32)      0         \n",
            "                                                                 \n",
            " conv2d_transpose_9 (Conv2DT  (None, 256, 256, 23)     2967      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,134,111\n",
            "Trainable params: 2,272,631\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH  = 256\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "\n",
        "\n",
        "# metrics=['accuracy']\n",
        "\n",
        "# def get_model():\n",
        "#     return multi_unet_model(n_classes= 23, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
        "\n",
        "\n",
        "\n",
        "X_train_data,X_val_data,X_test_data, Y_train_data,Y_val_data, Y_test_data = split_data(image, label)\n",
        "\n",
        "cal_data_set = tf.data.Dataset.zip((X_train_data, Y_train_data))\n",
        "val_data_set = tf.data.Dataset.zip((X_val_data,Y_val_data))\n",
        "test_data_set = tf.data.Dataset.zip((X_test_data,Y_test_data))\n",
        "# tf.debugging.set_log_device_placement(True)\n",
        "# gpus = tf.config.list_logical_devices('GPU')\n",
        "# strategy = tf.distribute.MirroredStrategy(gpus)\n",
        "\n",
        "\n",
        "metrics=['accuracy']\n",
        "\n",
        "def get_Xception_model():\n",
        "    base_model = tf.keras.applications.Xception(include_top=False,\n",
        "                                          weights='imagenet',\n",
        "                                          input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    base_model.trainable =False\n",
        "    temp=base_model(image.take(1).get_single_element())\n",
        "    print(temp.shape)\n",
        "    \n",
        "    inputs= tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    x = tf.keras.layers.LeakyReLU(alpha=.2)(x)\n",
        "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    x = tf.keras.layers.LeakyReLU(alpha=.2)(x)\n",
        "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    x = tf.keras.layers.LeakyReLU(alpha=.2)(x)\n",
        "    x = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    x = tf.keras.layers.LeakyReLU(alpha=.2)(x)\n",
        "    outputs = Conv2DTranspose(23, (2, 2), strides=(2, 2), activation='softmax')(x)\n",
        "    print(outputs.shape)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "metrics = ['accuracy']\n",
        "model = get_Xception_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n",
        "model.summary()\n",
        "model_dir = 'models1'\n",
        "pathlib.Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "cbk = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_dir+'/cp', monitor='val_accuracy', mode='max', \n",
        "    save_best_only=True, save_weights_only=True)\n",
        "\n",
        "\n",
        "## Define the resolution of the images and the number of classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuDHx8f4FBuD",
        "outputId": "6f5858f3-04c6-4a78-da16-4d9d59eba1f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "320/320 [==============================] - 1380s 4s/step - loss: 2.0663 - accuracy: 0.3865 - val_loss: 1.6279 - val_accuracy: 0.4805\n",
            "Epoch 2/5\n",
            "320/320 [==============================] - 1397s 4s/step - loss: 1.4858 - accuracy: 0.5577 - val_loss: 1.2826 - val_accuracy: 0.6056\n",
            "Epoch 3/5\n",
            "320/320 [==============================] - 1390s 4s/step - loss: 1.2573 - accuracy: 0.6230 - val_loss: 1.1884 - val_accuracy: 0.6346\n",
            "Epoch 4/5\n",
            "320/320 [==============================] - 1396s 4s/step - loss: 1.1573 - accuracy: 0.6501 - val_loss: 1.1512 - val_accuracy: 0.6487\n",
            "Epoch 5/5\n",
            "320/320 [==============================] - 1401s 4s/step - loss: 1.0933 - accuracy: 0.6654 - val_loss: 1.1153 - val_accuracy: 0.6587\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "history = model.fit(cal_data_set ,\n",
        "                    verbose=1, \n",
        "                    epochs=5, \n",
        "                    validation_data=val_data_set, \n",
        "                    shuffle=False,\n",
        "                    callbacks = cbk)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVMxE2MlQBA0",
        "outputId": "cdb4f7b4-2d31-4076-ea12-dbbd8f1163c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 214s 4s/step - loss: 1.2688 - accuracy: 0.6072\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2687828540802002, 0.6072200536727905]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "Untitled15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
